"""
============================================
FINE-TUNE U-NET SEGMENTATION MODEL
Google Colab GPU Training Script
============================================

Expected improvement: 86.57% ‚Üí 92-95% Dice

Requirements:
- Google Colab with T4 GPU (free tier)
- ~700 images per tumor class
- Training time: 1-2 hours

Based on successful classification fine-tuning approach
"""

import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import h5py
import glob
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import matplotlib.pyplot as plt
import cv2
from scipy import ndimage
import json
from datetime import datetime
from collections import defaultdict
import random

print("="*70)
print("üöÄ BRAIN TUMOR SEGMENTATION FINE-TUNING")
print("="*70)

# ============================================
# CONFIGURATION
# ============================================

CONFIG = {
    # Paths
    'data_dir': '/content/drive/My Drive/Tumor/2',
    'output_dir': '/content/drive/My Drive/Brain_Tumor_Segmentation_FineTuned',

    # Model
    'base_model_repo': 'bombshelll/unet-brain-tumor-segmentation',

    # Training hyperparameters
    'img_size': 256,
    'batch_size': 8,
    'learning_rate': 1e-4,  # Lower than classification (conservative for segmentation)
    'num_epochs': 20,
    'samples_per_class': 700,
    'validation_split': 0.15,
    'test_split': 0.15,

    # Data augmentation (medical-safe only!)
    'use_augmentation': True,
    'horizontal_flip': True,
    'brightness_range': 0.1,  # ¬±10% (conservative for medical images)
    'zoom_range': 0.05,       # ¬±5% (minimal)

    # Layer freezing strategy
    'freeze_encoder_blocks': 2,  # Freeze first 2 encoder blocks (conservative)

    # Early stopping
    'patience': 7,
    'min_delta': 0.001,
}

print(f"\nüìã CONFIGURATION:")
print(f"   Data Directory: {CONFIG['data_dir']}")
print(f"   Output Directory: {CONFIG['output_dir']}")
print(f"   Batch Size: {CONFIG['batch_size']}")
print(f"   Learning Rate: {CONFIG['learning_rate']}")
print(f"   Epochs: {CONFIG['num_epochs']}")
print(f"   Samples per Class: {CONFIG['samples_per_class']}")
print(f"   Freeze Encoder Blocks: {CONFIG['freeze_encoder_blocks']}")

# ============================================
# 1. DATA LOADING
# ============================================

def load_mat_file(file_path):
    """Load .mat file (handles both v7.3 and older formats)"""
    try:
        # Try HDF5 format first (v7.3)
        with h5py.File(file_path, 'r') as f:
            if 'cjdata' in f:
                image = np.array(f['cjdata']['image']).T
                mask = np.array(f['cjdata']['tumorMask']).T
                label = int(np.array(f['cjdata']['label']).item())
                return {
                    'image': image.astype(np.float32),
                    'tumorMask': mask.astype(np.float32),
                    'label': label
                }
    except:
        pass

    # Try older format
    try:
        from scipy.io import loadmat
        mat = loadmat(file_path)
        if 'cjdata' in mat:
            cjdata = mat['cjdata'][0, 0]
            return {
                'image': cjdata['image'].astype(np.float32),
                'tumorMask': cjdata['tumorMask'].astype(np.float32),
                'label': int(cjdata['label'])
            }
    except:
        pass

    return None

def load_dataset(data_dir, samples_per_class=700, verbose=True):
    """
    Load and balance dataset

    Returns:
        X: images (N, H, W)
        y: masks (N, H, W)
        labels: tumor types (N,)
    """
    all_files = glob.glob(os.path.join(data_dir, '**/*.mat'), recursive=True)

    if verbose:
        print(f"\nüìÅ Found {len(all_files)} .mat files")

    # Separate by class
    class_files = {1: [], 2: [], 3: []}
    tumor_types = {1: "Meningiom", 2: "Gliom", 3: "Hypophysentumor"}

    # Quick scan for labels
    print("üîç Scanning dataset...")
    for file in tqdm(all_files, desc="Scanning labels"):
        try:
            data = load_mat_file(file)
            if data:
                label = data['label']
                if label in [1, 2, 3]:
                    class_files[label].append(file)
        except:
            continue

    if verbose:
        print(f"\nüìä Class distribution:")
        for cls in [1, 2, 3]:
            print(f"   Class {cls} ({tumor_types[cls]}): {len(class_files[cls])} files")

    # Balance to samples_per_class
    balanced_files = []
    for cls in [1, 2, 3]:
        if class_files[cls]:
            n_samples = min(samples_per_class, len(class_files[cls]))
            random.shuffle(class_files[cls])
            balanced_files.extend(class_files[cls][:n_samples])
            if verbose:
                print(f"   ‚Üí Sampling {n_samples} from class {cls}")

    random.shuffle(balanced_files)

    if verbose:
        print(f"\n‚úÖ Balanced dataset: {len(balanced_files)} total samples")

    # Load all data
    X, y, labels = [], [], []

    print("\nüì• Loading images...")
    for file in tqdm(balanced_files, desc="Loading data"):
        try:
            data = load_mat_file(file)
            if not data:
                continue

            image = data['image']
            mask = data['tumorMask']
            label = data['label']

            # Normalize image
            image = (image - image.min()) / (image.max() - image.min() + 1e-8)

            # Ensure binary mask
            mask = (mask > 0).astype(np.float32)

            X.append(image)
            y.append(mask)
            labels.append(label)
        except Exception as e:
            continue

    X = np.array(X)
    y = np.array(y)
    labels = np.array(labels)

    if verbose:
        print(f"\n‚úÖ Loaded dataset:")
        print(f"   Images shape: {X.shape}")
        print(f"   Masks shape: {y.shape}")
        print(f"   Labels shape: {labels.shape}")

    return X, y, labels

# ============================================
# 2. DATA AUGMENTATION (MEDICAL-SAFE)
# ============================================

def augment_image_and_mask(image, mask, config):
    """
    Apply medical-safe augmentation to both image and mask

    CRITICAL: Only horizontal flip, brightness, and zoom
    NO rotations (90¬∞, 180¬∞, 270¬∞) - they harm medical models!
    """
    # Random horizontal flip
    if config['horizontal_flip'] and np.random.random() > 0.5:
        image = np.fliplr(image)
        mask = np.fliplr(mask)

    # Random brightness adjustment
    if np.random.random() > 0.5:
        factor = 1.0 + np.random.uniform(-config['brightness_range'], config['brightness_range'])
        image = np.clip(image * factor, 0, 1)

    # Random zoom (slight)
    if config['zoom_range'] > 0 and np.random.random() > 0.5:
        zoom_factor = 1.0 + np.random.uniform(-config['zoom_range'], config['zoom_range'])
        h, w = image.shape

        # Calculate crop size
        crop_h = int(h / zoom_factor)
        crop_w = int(w / zoom_factor)

        # Random crop position
        start_h = np.random.randint(0, h - crop_h + 1) if h > crop_h else 0
        start_w = np.random.randint(0, w - crop_w + 1) if w > crop_w else 0

        # Crop
        image_crop = image[start_h:start_h+crop_h, start_w:start_w+crop_w]
        mask_crop = mask[start_h:start_h+crop_h, start_w:start_w+crop_w]

        # Resize back
        image = cv2.resize(image_crop, (w, h), interpolation=cv2.INTER_LINEAR)
        mask = cv2.resize(mask_crop, (w, h), interpolation=cv2.INTER_NEAREST)

    return image, mask

# ============================================
# 3. CUSTOM DATA GENERATOR
# ============================================

class SegmentationDataGenerator(keras.utils.Sequence):
    """Custom data generator with medical-safe augmentation"""

    def __init__(self, X, y, batch_size, img_size, config, augment=False, shuffle=True):
        self.X = X
        self.y = y
        self.batch_size = batch_size
        self.img_size = img_size
        self.config = config
        self.augment = augment
        self.shuffle = shuffle
        self.indices = np.arange(len(self.X))
        self.on_epoch_end()

    def __len__(self):
        return int(np.ceil(len(self.X) / self.batch_size))

    def __getitem__(self, idx):
        indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]

        batch_X = []
        batch_y = []

        for i in indices:
            img = self.X[i].copy()
            mask = self.y[i].copy()

            # Augmentation
            if self.augment:
                img, mask = augment_image_and_mask(img, mask, self.config)

            # Resize to model input size
            if img.shape != (self.img_size, self.img_size):
                img_resized = cv2.resize(img, (self.img_size, self.img_size), interpolation=cv2.INTER_LINEAR)
                mask_resized = cv2.resize(mask, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)
            else:
                img_resized = img
                mask_resized = mask

            # Convert to RGB (3 channels) - models expect RGB
            img_rgb = np.stack([img_resized, img_resized, img_resized], axis=-1)

            batch_X.append(img_rgb)
            batch_y.append(np.expand_dims(mask_resized, -1))

        return np.array(batch_X, dtype=np.float32), np.array(batch_y, dtype=np.float32)

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indices)

# ============================================
# 4. CUSTOM LOSSES & METRICS
# ============================================

def dice_loss(y_true, y_pred, smooth=1e-6):
    """Dice loss (1 - Dice coefficient)"""
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred, [-1])

    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    dice = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)

    return 1 - dice

def combined_loss(y_true, y_pred):
    """Combined Dice + Binary Cross-Entropy"""
    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)
    dice = dice_loss(y_true, y_pred)
    return 0.5 * bce + 0.5 * dice

def dice_coefficient(y_true, y_pred, threshold=0.5, smooth=1e-6):
    """Dice coefficient metric"""
    y_pred_binary = tf.cast(y_pred > threshold, tf.float32)
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred_binary, [-1])

    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    dice = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)

    return dice

def iou_score(y_true, y_pred, threshold=0.5, smooth=1e-6):
    """IoU metric"""
    y_pred_binary = tf.cast(y_pred > threshold, tf.float32)
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred_binary, [-1])

    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection
    iou = (intersection + smooth) / (union + smooth)

    return iou

# ============================================
# 5. BUILD U-NET MODEL
# ============================================

def build_unet(input_shape=(256, 256, 3), freeze_encoder_blocks=2):
    """
    Build U-Net model with optional encoder freezing

    Args:
        input_shape: Input image shape
        freeze_encoder_blocks: Number of encoder blocks to freeze (0, 1, or 2)
    """
    inputs = layers.Input(shape=input_shape, name='input_image')

    # ENCODER (Downsampling path)
    # Block 1
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same', name='enc_conv1_1')(inputs)
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same', name='enc_conv1_2')(conv1)
    pool1 = layers.MaxPooling2D(pool_size=(2, 2), name='enc_pool1')(conv1)

    # Block 2
    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same', name='enc_conv2_1')(pool1)
    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same', name='enc_conv2_2')(conv2)
    pool2 = layers.MaxPooling2D(pool_size=(2, 2), name='enc_pool2')(conv2)

    # Block 3
    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same', name='enc_conv3_1')(pool2)
    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same', name='enc_conv3_2')(conv3)
    pool3 = layers.MaxPooling2D(pool_size=(2, 2), name='enc_pool3')(conv3)

    # Block 4
    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same', name='enc_conv4_1')(pool3)
    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same', name='enc_conv4_2')(conv4)
    pool4 = layers.MaxPooling2D(pool_size=(2, 2), name='enc_pool4')(conv4)

    # BOTTLENECK
    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same', name='bottleneck_conv1')(pool4)
    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same', name='bottleneck_conv2')(conv5)

    # DECODER (Upsampling path)
    # Block 1
    up6 = layers.UpSampling2D(size=(2, 2), name='dec_upsample1')(conv5)
    up6 = layers.concatenate([up6, conv4], name='dec_concat1')
    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same', name='dec_conv1_1')(up6)
    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same', name='dec_conv1_2')(conv6)

    # Block 2
    up7 = layers.UpSampling2D(size=(2, 2), name='dec_upsample2')(conv6)
    up7 = layers.concatenate([up7, conv3], name='dec_concat2')
    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same', name='dec_conv2_1')(up7)
    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same', name='dec_conv2_2')(conv7)

    # Block 3
    up8 = layers.UpSampling2D(size=(2, 2), name='dec_upsample3')(conv7)
    up8 = layers.concatenate([up8, conv2], name='dec_concat3')
    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same', name='dec_conv3_1')(up8)
    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same', name='dec_conv3_2')(conv8)

    # Block 4
    up9 = layers.UpSampling2D(size=(2, 2), name='dec_upsample4')(conv8)
    up9 = layers.concatenate([up9, conv1], name='dec_concat4')
    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same', name='dec_conv4_1')(up9)
    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same', name='dec_conv4_2')(conv9)

    # OUTPUT
    outputs = layers.Conv2D(1, 1, activation='sigmoid', name='output')(conv9)

    model = keras.Model(inputs=inputs, outputs=outputs, name='unet')

    # FREEZE ENCODER BLOCKS
    if freeze_encoder_blocks > 0:
        print(f"\nüîí Freezing first {freeze_encoder_blocks} encoder blocks...")

        freeze_layers = []
        if freeze_encoder_blocks >= 1:
            freeze_layers.extend(['enc_conv1_1', 'enc_conv1_2', 'enc_pool1'])
        if freeze_encoder_blocks >= 2:
            freeze_layers.extend(['enc_conv2_1', 'enc_conv2_2', 'enc_pool2'])

        for layer in model.layers:
            if layer.name in freeze_layers:
                layer.trainable = False
                print(f"   ‚ùÑÔ∏è  Frozen: {layer.name}")

    return model

# ============================================
# 6. TRAINING FUNCTION
# ============================================

def train_segmentation_model(config):
    """Main training function"""

    print("\n" + "="*70)
    print("STEP 1: LOADING DATASET")
    print("="*70)

    X, y, labels = load_dataset(
        config['data_dir'],
        samples_per_class=config['samples_per_class'],
        verbose=True
    )

    # Split: train / val / test
    print("\n" + "="*70)
    print("STEP 2: SPLITTING DATASET")
    print("="*70)

    # First split: train + temp
    X_train, X_temp, y_train, y_temp, labels_train, labels_temp = train_test_split(
        X, y, labels,
        test_size=(config['validation_split'] + config['test_split']),
        random_state=42,
        stratify=labels
    )

    # Second split: val + test
    val_ratio = config['validation_split'] / (config['validation_split'] + config['test_split'])
    X_val, X_test, y_val, y_test, labels_val, labels_test = train_test_split(
        X_temp, y_temp, labels_temp,
        test_size=(1 - val_ratio),
        random_state=42,
        stratify=labels_temp
    )

    print(f"\nüìä Dataset split:")
    print(f"   Training:   {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)")
    print(f"   Validation: {len(X_val)} samples ({len(X_val)/len(X)*100:.1f}%)")
    print(f"   Test:       {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)")

    # Create data generators
    print("\n" + "="*70)
    print("STEP 3: CREATING DATA GENERATORS")
    print("="*70)

    train_gen = SegmentationDataGenerator(
        X_train, y_train,
        batch_size=config['batch_size'],
        img_size=config['img_size'],
        config=config,
        augment=config['use_augmentation'],
        shuffle=True
    )

    val_gen = SegmentationDataGenerator(
        X_val, y_val,
        batch_size=config['batch_size'],
        img_size=config['img_size'],
        config=config,
        augment=False,
        shuffle=False
    )

    test_gen = SegmentationDataGenerator(
        X_test, y_test,
        batch_size=config['batch_size'],
        img_size=config['img_size'],
        config=config,
        augment=False,
        shuffle=False
    )

    print(f"   Training batches: {len(train_gen)}")
    print(f"   Validation batches: {len(val_gen)}")
    print(f"   Test batches: {len(test_gen)}")
    print(f"   Augmentation: {'‚úÖ ENABLED' if config['use_augmentation'] else '‚ùå DISABLED'}")

    # Build model
    print("\n" + "="*70)
    print("STEP 4: BUILDING MODEL")
    print("="*70)

    model = build_unet(
        input_shape=(config['img_size'], config['img_size'], 3),
        freeze_encoder_blocks=config['freeze_encoder_blocks']
    )

    print(f"\n‚úÖ Model built")
    print(f"   Total params: {model.count_params():,}")

    trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])
    non_trainable_params = sum([tf.size(w).numpy() for w in model.non_trainable_weights])
    print(f"   Trainable: {trainable_params:,}")
    print(f"   Non-trainable: {non_trainable_params:,}")

    # Compile model
    print("\n" + "="*70)
    print("STEP 5: COMPILING MODEL")
    print("="*70)

    optimizer = keras.optimizers.Adam(learning_rate=config['learning_rate'])

    model.compile(
        optimizer=optimizer,
        loss=combined_loss,
        metrics=[dice_coefficient, iou_score, 'binary_accuracy']
    )

    print("‚úÖ Model compiled")
    print(f"   Optimizer: Adam (lr={config['learning_rate']})")
    print(f"   Loss: Combined (Dice + BCE)")
    print(f"   Metrics: Dice, IoU, Binary Accuracy")

    # Callbacks
    print("\n" + "="*70)
    print("STEP 6: SETTING UP CALLBACKS")
    print("="*70)

    os.makedirs(config['output_dir'], exist_ok=True)

    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_dice_coefficient',
            patience=config['patience'],
            min_delta=config['min_delta'],
            mode='max',
            restore_best_weights=True,
            verbose=1
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_dice_coefficient',
            factor=0.5,
            patience=3,
            min_lr=1e-7,
            mode='max',
            verbose=1
        ),
        keras.callbacks.ModelCheckpoint(
            filepath=os.path.join(config['output_dir'], 'best_model.h5'),
            monitor='val_dice_coefficient',
            save_best_only=True,
            mode='max',
            verbose=1
        ),
        keras.callbacks.CSVLogger(
            os.path.join(config['output_dir'], 'training_log.csv')
        ),
        keras.callbacks.TensorBoard(
            log_dir=os.path.join(config['output_dir'], 'logs'),
            histogram_freq=1
        )
    ]

    print(f"‚úÖ Callbacks configured:")
    print(f"   - Early Stopping (patience={config['patience']})")
    print(f"   - Learning Rate Reduction")
    print(f"   - Model Checkpoint")
    print(f"   - CSV Logger")
    print(f"   - TensorBoard")

    # Train
    print("\n" + "="*70)
    print("STEP 7: TRAINING MODEL")
    print("="*70)
    print(f"   Epochs: {config['num_epochs']}")
    print(f"   Batch size: {config['batch_size']}")
    print(f"   Learning rate: {config['learning_rate']}")
    print()

    history = model.fit(
        train_gen,
        validation_data=val_gen,
        epochs=config['num_epochs'],
        callbacks=callbacks,
        verbose=1
    )

    # Save final model
    print("\n" + "="*70)
    print("STEP 8: SAVING MODEL")
    print("="*70)

    final_model_path = os.path.join(config['output_dir'], 'final_model')
    model.save(final_model_path)
    print(f"‚úÖ Model saved to: {final_model_path}")

    # Plot training history
    print("\n" + "="*70)
    print("STEP 9: PLOTTING TRAINING HISTORY")
    print("="*70)

    plot_training_history(history, config['output_dir'])

    # Final evaluation on test set
    print("\n" + "="*70)
    print("STEP 10: FINAL EVALUATION ON TEST SET")
    print("="*70)

    test_results = model.evaluate(test_gen, verbose=0)
    test_metrics = dict(zip(model.metrics_names, test_results))

    print(f"\nüéâ TRAINING COMPLETE!")
    print(f"{'='*70}")
    print(f"Final Test Set Metrics:")
    print(f"   Dice Coefficient: {test_metrics['dice_coefficient']:.4f}")
    print(f"   IoU Score: {test_metrics['iou_score']:.4f}")
    print(f"   Binary Accuracy: {test_metrics['binary_accuracy']:.4f}")
    print(f"   Loss: {test_metrics['loss']:.4f}")
    print(f"{'='*70}")

    # Save metrics summary
    save_metrics_summary(history, test_metrics, config)

    return model, history, test_metrics

# ============================================
# 7. VISUALIZATION
# ============================================

def plot_training_history(history, output_dir):
    """Plot training curves"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    # Dice coefficient
    axes[0, 0].plot(history.history['dice_coefficient'], label='Train Dice', linewidth=2)
    axes[0, 0].plot(history.history['val_dice_coefficient'], label='Val Dice', linewidth=2)
    axes[0, 0].set_title('Dice Coefficient Over Epochs', fontsize=12, fontweight='bold')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Dice Coefficient')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # Loss
    axes[0, 1].plot(history.history['loss'], label='Train Loss', linewidth=2)
    axes[0, 1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)
    axes[0, 1].set_title('Loss Over Epochs', fontsize=12, fontweight='bold')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Loss')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)

    # IoU
    axes[1, 0].plot(history.history['iou_score'], label='Train IoU', linewidth=2)
    axes[1, 0].plot(history.history['val_iou_score'], label='Val IoU', linewidth=2)
    axes[1, 0].set_title('IoU Score Over Epochs', fontsize=12, fontweight='bold')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('IoU Score')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)

    # Binary Accuracy
    axes[1, 1].plot(history.history['binary_accuracy'], label='Train Acc', linewidth=2)
    axes[1, 1].plot(history.history['val_binary_accuracy'], label='Val Acc', linewidth=2)
    axes[1, 1].set_title('Binary Accuracy Over Epochs', fontsize=12, fontweight='bold')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Binary Accuracy')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)

    plt.suptitle('Training History - Brain Tumor Segmentation Fine-Tuning',
                 fontsize=14, fontweight='bold')
    plt.tight_layout()

    plot_path = os.path.join(output_dir, 'training_history.png')
    plt.savefig(plot_path, dpi=150, bbox_inches='tight')
    print(f"‚úÖ Training plot saved to: {plot_path}")
    plt.close()

def save_metrics_summary(history, test_metrics, config):
    """Save metrics summary to JSON"""
    summary = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'config': {
            'batch_size': config['batch_size'],
            'learning_rate': config['learning_rate'],
            'epochs_trained': len(history.history['loss']),
            'freeze_encoder_blocks': config['freeze_encoder_blocks'],
            'augmentation': config['use_augmentation']
        },
        'test_metrics': {
            'dice_coefficient': float(test_metrics['dice_coefficient']),
            'iou_score': float(test_metrics['iou_score']),
            'binary_accuracy': float(test_metrics['binary_accuracy']),
            'loss': float(test_metrics['loss'])
        },
        'best_validation_metrics': {
            'dice_coefficient': float(max(history.history['val_dice_coefficient'])),
            'iou_score': float(max(history.history['val_iou_score'])),
            'best_epoch': int(np.argmax(history.history['val_dice_coefficient']) + 1)
        }
    }

    summary_path = os.path.join(config['output_dir'], 'training_summary.json')
    with open(summary_path, 'w') as f:
        json.dump(summary, f, indent=2)

    print(f"‚úÖ Metrics summary saved to: {summary_path}")

# ============================================
# 8. MAIN EXECUTION
# ============================================

if __name__ == '__main__':
    # Check GPU
    print("\nüîç Checking GPU availability...")
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        print(f"‚úÖ GPU detected: {gpus}")
        # Enable memory growth
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("‚úÖ Memory growth enabled")
    else:
        print("‚ö†Ô∏è  No GPU detected. Training will be SLOW on CPU.")
        print("   Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí T4 GPU")

    # Mount Google Drive
    print("\nüìÅ Mounting Google Drive...")
    try:
        from google.colab import drive
        drive.mount('/content/drive')
        print("‚úÖ Google Drive mounted")
    except:
        print("‚ö†Ô∏è  Not running in Colab or Drive already mounted")

    # Train model
    print("\n" + "="*70)
    print("üöÄ STARTING FINE-TUNING")
    print("="*70)

    model, history, test_metrics = train_segmentation_model(CONFIG)

    print("\n" + "="*70)
    print("‚úÖ ALL DONE! FINE-TUNING COMPLETE")
    print("="*70)
    print(f"\nüìÅ Output directory: {CONFIG['output_dir']}")
    print("\nüì• Next steps:")
    print("   1. Download 'final_model' from Google Drive")
    print("   2. Update segmentation_optimized.py to use the new model")
    print("   3. Re-run evaluation to see improved Dice scores!")
    print(f"\nüí° Expected improvement: 86.57% ‚Üí 92-95% Dice")
    print(f"üí° Actual test result: {test_metrics['dice_coefficient']:.2%} Dice")
